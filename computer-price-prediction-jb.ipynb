{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13192928,"sourceType":"datasetVersion","datasetId":8360593}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Computer price Notebook","metadata":{}},{"cell_type":"markdown","source":"### Introduction","metadata":{}},{"cell_type":"markdown","source":"To put it simple, we want to predict the retail price of laptops and desktops based on their hardware specifications.\n\nThis model will help us detect if a computer is valued fairly or not.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport kagglehub\nimport os\n\n# Download latest version\npath = kagglehub.dataset_download(\"paperxd/all-computer-prices\")\n\nprint(\"Path to dataset files:\", path)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\ndef adjusted_r2_score(y_true, y_pred, n_features):\n    r2 = r2_score(y_true, y_pred)\n    adjusted_r2 = 1 - ((1 - r2) * (n_features - 1)) / ((len(y_true) - n_features - 1))\n    return adjusted_r2\n\ndef print_errors(actual, pred, n_feat):\n  print(\"\\tR2: \" + str(r2_score(actual, pred)))\n  print(\"\\tAdjusted R2: \" + str(adjusted_r2_score(actual, pred, n_feat)))\n  print(\"\\tMSE: \" + str(mean_squared_error(actual, pred)))\n  print(\"\\tMAE: \" + str(mean_absolute_error(actual, pred)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T15:42:41.419535Z","iopub.execute_input":"2025-11-03T15:42:41.419855Z","iopub.status.idle":"2025-11-03T15:42:43.224968Z","shell.execute_reply.started":"2025-11-03T15:42:41.419819Z","shell.execute_reply":"2025-11-03T15:42:43.223444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir(path))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"csv_path = f\"{path}/computer_prices_all.csv\"\ndf = pd.read_csv(csv_path)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(10)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"To make the EDA easier, we will use ProfileReport","metadata":{}},{"cell_type":"code","source":"from ydata_profiling import ProfileReport","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"computer_report = ProfileReport(df)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"computer_report.to_file('computer_report.html')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Checking for duplicates","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Checking for Na values","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_cols = df_1.select_dtypes(include=['int64', 'float64']).columns","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.heatmap(df_1[numerical_cols].corr(), cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix = df_1[numerical_cols].corr()\ncorr_series = corr_matrix.unstack()\ncorr_series = corr_series[corr_series.index.get_level_values(0) != corr_series.index.get_level_values(1)]\ncorr_series = corr_series.abs().sort_values(ascending=False)\ncorr_series = corr_series[~corr_series.index.duplicated(keep='first')]\ncorr_df = pd.DataFrame(corr_series).reset_index()\ncorr_df.columns = ['Feature_1', 'Feature_2', 'Correlation']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_df","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_df[corr_df['Correlation'] >= 0.85]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"For the release year column, I will replace it for a years_since_release column\nI will copy the original df to keep it intact ","metadata":{}},{"cell_type":"code","source":"df_1 = df.copy()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_1['years_since_release'] = 2025 - df_1['release_year']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_1.drop(columns='release_year', inplace = True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_1[['cpu_model', 'cpu_tier', 'cpu_cores', 'cpu_threads', 'cpu_base_ghz', 'cpu_boost_ghz']][df_1[\"cpu_model\"] == 'Intel i5-11129']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"After checking this example, I noticed that the cpu_model column might not be significant for our model, so we will drop this column. We can asume the same for the gpu_model column. The other cpu and gpu columns already capture the specifications.\n\nI will also remove the general model column","metadata":{}},{"cell_type":"code","source":"df_1.drop(columns=['cpu_model','gpu_model'], inplace=True)\ndf_1.drop(columns=['model'], inplace=True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Checking for all the categorical columns left ","metadata":{}},{"cell_type":"code","source":"categorical_cols = df_1.select_dtypes(include=[\"object\", \"category\"]).columns\ncategorical_cols","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The resolution can be broken down into width and height","metadata":{}},{"cell_type":"code","source":"df_1[['width', 'height']] = df_1['resolution'].str.split('x', expand=True).astype(int)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can drop the resolution column","metadata":{}},{"cell_type":"code","source":"df_1.drop(columns='resolution', inplace=True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using these two numbers we can create two new columns, total_pixels and aspect_ratio ","metadata":{}},{"cell_type":"code","source":"df_1['total_pixels'] = df_1['width'] * df_1['height']\ndf_1['aspect_ratio'] = df_1['width'] / df_1['height']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we drop the width and height columns","metadata":{}},{"cell_type":"code","source":"df_1.drop(columns=['width', 'height'], inplace=True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The bluetooth feature also acts as a categorical value ","metadata":{}},{"cell_type":"code","source":"df_1['bluetooth'].value_counts()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_1['bluetooth'] = df_1['bluetooth'].astype(str)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_1_enhanced = df_1.copy()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we add some extra features","metadata":{}},{"cell_type":"code","source":"# Some feature engineering\ndf_1_enhanced[\"performance_per_core\"] = df_1_enhanced[\"cpu_base_ghz\"] * df_1_enhanced[\"cpu_cores\"]\ndf_1_enhanced[\"boost_per_core\"] = df_1_enhanced[\"cpu_boost_ghz\"] * df_1_enhanced[\"cpu_cores\"]\ndf_1_enhanced[\"ram_per_core\"] = df_1_enhanced[\"ram_gb\"] / df_1_enhanced[\"cpu_cores\"].replace(0, np.nan)\ndf_1_enhanced[\"storage_per_drive\"] = df_1_enhanced[\"storage_gb\"] / df_1_enhanced[\"storage_drive_count\"].replace(0, np.nan)\ndf_1_enhanced[\"battery_efficiency\"] = df_1_enhanced[\"battery_wh\"] / df_1_enhanced[\"weight_kg\"].replace(0, np.nan)\ndf_1_enhanced[\"ppi\"] = (df_1_enhanced[\"total_pixels\"] ** 0.5) / df_1_enhanced[\"display_size_in\"].replace(0, np.nan)\n\n# extras\ndf_1_enhanced[\"total_performance_tier\"] = df_1_enhanced[\"cpu_tier\"] + df_1_enhanced[\"gpu_tier\"]\ndf_1_enhanced[\"performance_age_ratio\"] = (df_1_enhanced[\"cpu_boost_ghz\"] * df_1_enhanced[\"cpu_cores\"]) / (1 + df_1_enhanced[\"years_since_release\"])\n\n# replace inf/nan if division by zero\ndf_1_enhanced.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf_1_enhanced.fillna(0, inplace=True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For the rest of these columns, we can onehot encode","metadata":{}},{"cell_type":"code","source":"categorical_cols = df_1.select_dtypes(include=[\"object\", \"category\"]).columns","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_cols","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"First we create our train and test ","metadata":{}},{"cell_type":"code","source":"X = df_1_enhanced.drop(columns='price')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = df_1_enhanced['price']","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y.skew()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = X.select_dtypes(include=['int64', 'float64']).columns","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skew_values = X[num_cols].skew().sort_values(ascending=False)\nskew_values","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We proceed to One Hot Encode","metadata":{}},{"cell_type":"code","source":"encoder = OneHotEncoder(drop='first')\nencoded_train = encoder.fit_transform(X_train[categorical_cols]).toarray()\nencoded_test = encoder.transform(X_test[categorical_cols]).toarray()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transformed_train = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out())\ndf_transformed_test = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_encoded = pd.concat([X_train.drop(columns=categorical_cols).reset_index(), df_transformed_train], axis=1).drop(columns='index')\nX_test_encoded = pd.concat([X_test.drop(columns=categorical_cols).reset_index(), df_transformed_test], axis=1).drop(columns='index')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_encoded","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_scaled = X_train_encoded.copy()\nX_test_scaled = X_test_encoded.copy()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_scaled[num_cols] = scaler.fit_transform(X_train_encoded[num_cols])\nX_test_scaled[num_cols] = scaler.transform(X_test_encoded[num_cols])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Applying some models","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor  \n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    'lin': {\n        'model': LinearRegression(), \n        'scaled': True, \n        'params': {}\n    },\n    'gb': {\n        'model': GradientBoostingRegressor(),\n        'scaled': False,\n        'params': {'n_estimators': [100, 300], 'learning_rate': [0.05, 0.1], 'max_depth': [3, 5], 'subsample': [0.8, 1.0]\n        }\n    },\n    'dt': {\n        'model': DecisionTreeRegressor(),\n        'scaled': False,\n        'params': {'max_depth': [7, 10, 15], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]\n        }\n    },\n    'rf': {\n        'model': RandomForestRegressor(),\n        'scaled': False,\n        'params': {'max_depth': [7, 10, 15], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2]\n        }\n    },\n    'xgb': {\n        'model': XGBRegressor(n_jobs=-1),\n        'scaled': False,\n        'params': {'n_estimators': [100, 200], 'learning_rate': [0.03, 0.1, 0.3], 'max_depth': [3, 5, 7, 10], 'subsample': [0.7, 1.0], 'colsample_bytree': [0.7, 1.0]\n        }\n    },\n    'lgbm': {\n        'model': LGBMRegressor(random_state=42),\n        'scaled': False,  \n        'params': {'n_estimators': [300, 500], 'max_depth': [5, 10], 'learning_rate': [0.05, 0.1], 'num_leaves': [31, 63], 'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0]   \n        }\n    }  \n}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_models = []\n\nfor name, details in models.items():\n    gscv = GridSearchCV(details['model'], details['params'], cv=3, scoring='r2', n_jobs=-1)\n    X_train_final = X_train_scaled\n    if details['scaled'] == True:\n        X_train_final = X_train_scaled\n        X_test_final = X_test_scaled\n    else:\n        X_train_final = X_train_encoded\n        X_test_final = X_test_encoded\n    gscv.fit(X_train_final, y_train)\n\n    final_models.append({\n    'model': name,\n    'train_score': gscv.score(X_train_final, y_train),\n    'test_score': gscv.score(X_test_final, y_test),\n    'best_score': gscv.best_score_,\n    'best_params': gscv.best_params_})","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_models_df = pd.DataFrame(final_models)\nfinal_models_df","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lets try to find the best hyper parameters for XGB","metadata":{}},{"cell_type":"code","source":"param_distributions = {\n    'n_estimators': [100, 200, 400, 600],          \n    'max_depth': [3, 4, 5, 6, 8, 10],              \n    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2], \n    'subsample': [0.6, 0.8, 1.0],                  \n    'colsample_bytree': [0.6, 0.8, 1.0],           \n    'gamma': [0, 0.1, 0.3, 0.5, 1],                \n    'min_child_weight': [1, 3, 5, 7],              \n    'reg_alpha': [0, 0.001, 0.01, 0.1, 1, 10],     \n    'reg_lambda': [0.1, 1, 5, 10, 20],             \n    'booster': ['gbtree'],                         \n    'tree_method': ['hist'],           \n    'random_state': [42]\n}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb = XGBRegressor()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_cv = RandomizedSearchCV(\n    estimator=xgb,\n    param_distributions=param_distributions,\n    n_iter=40,            \n    scoring='r2',\n    cv=3,\n    verbose=2,\n    n_jobs=-1,\n    random_state=42\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_cv.fit(X_train_encoded, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Best parameters:\", random_cv.best_params_)\nprint(\"Best cross-val R2:\", random_cv.best_score_)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb = XGBRegressor(**random_cv.best_params_)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb.fit(X_train_encoded, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"** XGB Regressor TRAIN **\")\nn_features = X_train.shape[1]\ny_train_predicted_xgb = xgb.predict(X_train_encoded)\nprint_errors(y_train, y_train_predicted_xgb, n_features)\n\nprint(\"** XGB Regressor TEST **\")\ny_test_predicted_xgb = xgb.predict(X_test_encoded)\nprint_errors(y_test, y_test_predicted_xgb, n_features)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb.score(X_train_encoded, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"\\nXGB Cross-Validation R2 Score: {xgb_scores.mean():.3f} ± {xgb_scores.std():.3f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  Stacking Regressor","metadata":{}},{"cell_type":"markdown","source":"We will use LinearRegression as our final estimator","metadata":{}},{"cell_type":"code","source":"estimators = [\n    ('lin', LinearRegression(**final_models_df.loc[final_models_df['model'] == 'lin']['best_params'].iloc[0])),\n    ('gb', GradientBoostingRegressor(**final_models_df.loc[final_models_df['model'] == 'lin']['best_params'].iloc[0])),\n    ('xgb', XGBRegressor(**random_cv.best_params_)),\n    ('lgbm', LGBMRegressor(**final_models_df.loc[final_models_df['model'] == 'lin']['best_params'].iloc[0]))\n]\n\nstacking_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\nstacking_model.fit(X_train_encoded, y_train)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train_predicted = stacking_model.predict(X_train_encoded)\ny_test_predicted = stacking_model.predict(X_test_encoded)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"** Stacking Regressor TRAIN **\")\nn_features = X_train.shape[1]\ny_train_predicted = stacking_model.predict(X_train_encoded)\nprint_errors(y_train, y_train_predicted, n_features)\n\nprint(\"** Stacking Regressor TEST **\")\ny_test_predicted = stacking_model.predict(X_test_encoded)\nprint_errors(y_test, y_test_predicted, n_features)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cross-validation for the stacking model","metadata":{}},{"cell_type":"code","source":"stacking_scores = cross_val_score(stacking_model, X_train_encoded, y_train, cv=3, scoring='r2', n_jobs=-1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"\\nStacking Model Cross-Validation R2 Score: {stacking_scores.mean():.3f} ± {stacking_scores.std():.3f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" Plot the Actual Price vs Predicted price chart","metadata":{}},{"cell_type":"code","source":"results_df = pd.DataFrame({\n    'Actual Price': y_test,\n    'Predicted Price': y_test_predicted\n})","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.scatterplot(x='Actual Price', y='Predicted Price', data=results_df, alpha=0.6)\nsns.lineplot(x=[results_df['Actual Price'].min(), results_df['Actual Price'].max()],\n             y=[results_df['Actual Price'].min(), results_df['Actual Price'].max()],\n             color='red', lw=2)\nplt.title(\"Actual vs. Predicted Price\")\nplt.xlabel(\"Actual Price\")\nplt.ylabel(\"Predicted Price\")\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"With Stacking, we get a slightly better result ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Importance and Interpretability","metadata":{}},{"cell_type":"code","source":"feature_importance = pd.DataFrame({\n    'Feature': X_train_encoded.columns,\n    'Importance': xgb.feature_importances_\n}).sort_values(by='Importance', ascending=False)\nprint(\"\\nFeature Importance (XGB):\")\nprint(feature_importance)\n\nfeature_importance_top = feature_importance.sort_values(by='Importance', ascending=False).head(16)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.barplot(x='Importance', y='Feature', data=feature_importance_top)\nplt.title('XGB Feature Importance')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_sample = X_test_encoded.sample(frac=0.1, random_state=42)\nexplainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(X_test_sample)\nplt.figure(figsize=(5, 6))\nshap.summary_plot(shap_values, X_test_sample, feature_names=X_test_encoded.columns, show=False)\nplt.title('SHAP Feature Importance for XGB')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Both graphs indicate that a laptop’s overall performance and hardware capacity significantly influence its predicted price. The total performance tier and RAM size stand out as the top contributors, meaning faster processors and more memory strongly increase value. \n\nApple products and macOS also add a clear brand premium, placing those laptops consistently at higher price points. Higher-end displays (OLED or Mini-LED) and powerful GPUs further signal premium devices, while lower pixel density or basic panels correspond to more affordable models.\n\nSecondary features, such as battery efficiency, ultrabook form factor, and larger or faster storage, add smaller but still positive effects. Conversely, older models or those with weaker performance tiers slightly reduce the predicted price. Overall","metadata":{}},{"cell_type":"markdown","source":"Lets now save the model","metadata":{}},{"cell_type":"code","source":"import joblib","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"joblib.dump(\n    stacking_model,\n    '/Users/joseborges/Kaggle projects/Computers/stacking_model_computers.pkl'\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_df = pd.DataFrame({\n    'Actual': y_test,\n    'Predicted': y_test_predicted\n})\npred_df.to_csv(\n    '/Users/joseborges/Kaggle projects/Computers/predictions.csv',\n    index=False\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Please upvote my notebook if you find it useful ","metadata":{}},{"cell_type":"markdown","source":"![](https://static.wikia.nocookie.net/smiling-friends/images/e/e6/Glep_%28SF%29.png)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}